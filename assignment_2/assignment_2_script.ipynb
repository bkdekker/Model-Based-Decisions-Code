{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4062f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "#from pathlib import Path\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "#from collections import Counter\n",
    "#import seaborn as sns\n",
    "#import sys\n",
    "#import os\n",
    "from Granovetter_experiment_results import (\n",
    "    #function draws treshold values for each node in G, \n",
    "    #mode determines how treshold values are generated\n",
    "    #each node samples tershold from specified distribution\n",
    "    #phi mean and phistd control mean and stdv of distribution\n",
    "    #inputs = G, mode, phi_mean, phi_std\n",
    "    draw_thresholds, \n",
    "    #simulates treshold dynamics on graph G\n",
    "    #input = G, list of seeds, dict of tresholds, max_nr_steps \n",
    "    #returns dictionary with time series of adopted nodes and numpy array\n",
    "    # of adopted nodes over time (history)\n",
    "    threshold_dynamics,\n",
    "    #input = adopted nodes\n",
    "    final_adoption_fraction,\n",
    "    #function to calculate the time to reach a target fraction of adopted nodes\n",
    "    #inputs = history, target=0.5)\n",
    "    time_to_fraction,\n",
    "    #random seeds\n",
    "    random_seeds,\n",
    "    #select top-B nodes with highest degree in graph G\n",
    "    high_degree_seeds,\n",
    "    #does same as for degree, uses a list comprehension and a lambda function\n",
    "    #lambda function takes tuple x = (node,betweenness_value) and returns the second\n",
    "    # value b which is the betweenness centrality(x[1]) in descending order\n",
    "    # [:B] takes the first B entries from the sorted list, which are the nodes with the highest betweenness centrality.\n",
    "    #inputs = G, B\n",
    "    betweenness_seeds,\n",
    "    #this funciton seeds the network with B nodes with highest core centrality nunmber,\n",
    "    # core nr is nr of nodes that are connected to all its neighbors\n",
    "    # for given graph G, the core number of a node v is the largest value k such that v is in a k-core.\n",
    "    #other words: tells you how deeply embedded a node is within the network's core structure.\n",
    "    #higher core number means node is more central to the network's connectivity\n",
    "    #inputs = G, B\n",
    "    kcore_seeds,\n",
    "    #estimates the spread of the treshold dynamics on graph G\n",
    "    #it runs the treshold dynamics R times, with different random seeds and tressholds\n",
    "    #returns the average final adoption fraction\n",
    "    #input = G, seeds, B, thresholds, R=5, max_steps =100\n",
    "    estimate_spread,\n",
    "    \n",
    "    run_experiments\n",
    ") \n",
    "Random_seed = 42\n",
    "random.seed(Random_seed)\n",
    "np.random.seed(Random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38a236d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store nodes and edges data\n",
    "def load_data(nodes, edges):\n",
    "\n",
    "    nodes = pd.read_csv(nodes)\n",
    "    edges = pd.read_csv(\n",
    "        edges,\n",
    "        header=None,\n",
    "        names=[\"source_new_id\", \"target_new_id\"],\n",
    "    )\n",
    "    # merge to get page names\n",
    "    df_merged = (\n",
    "        edges\n",
    "        .merge(nodes[['new_id', 'name']], left_on='source_new_id', right_on='new_id')\n",
    "        .rename(columns={'name': 'page_name_1'})\n",
    "        .drop('new_id', axis=1)\n",
    "        .merge(nodes[['new_id', 'name']], left_on='target_new_id', right_on='new_id')\n",
    "        .rename(columns={'name': 'page_name_2'})\n",
    "        .drop('new_id', axis=1)\n",
    "        .rename(columns={\n",
    "            'source_new_id': 'page_id_1',\n",
    "            'target_new_id': 'page_id_2'\n",
    "        })\n",
    "    )\n",
    "    print(nodes.size)\n",
    "    print(edges.size)\n",
    "    return df_merged, nodes, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2976be5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34677\n",
      "134228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(       page_id_1  page_id_2    page_name_1  \\\n",
       " 0              0       1490         LubaTV   \n",
       " 1              0       2742         LubaTV   \n",
       " 2              0       7265         LubaTV   \n",
       " 3              0       8076         LubaTV   \n",
       " 4              0       8844         LubaTV   \n",
       " ...          ...        ...            ...   \n",
       " 67094      11441      11479  David Kempton   \n",
       " 67095      10900      11486  David Grutman   \n",
       " 67096      11465      11528    A'N'D Lucia   \n",
       " 67097      11468      11513      Joe Rogan   \n",
       " 67098      11479      11527   John McVeigh   \n",
       " \n",
       "                                 page_name_2  \n",
       " 0                           Erick Krominski  \n",
       " 1                              Kim RosaCuca  \n",
       " 2                                Hugo Gloss  \n",
       " 3                                  CutiePie  \n",
       " 4                              Jayde Pierce  \n",
       " ...                                     ...  \n",
       " 67094                          John McVeigh  \n",
       " 67095                     MACK ON THE RADIO  \n",
       " 67096                        A'N'D 鍾羽Eunice  \n",
       " 67097  Taynara Germany's next Topmodel 2016  \n",
       " 67098                          Leila Abukar  \n",
       " \n",
       " [67099 rows x 4 columns],\n",
       "                      id                                name  new_id\n",
       " 0       116999698310182                           Mike Rowe    8980\n",
       " 1      1173678312659310                  Louis Ng Kok Kwang    2230\n",
       " 2       466981723395173                     Pastor Everaldo    7510\n",
       " 3       251453648389404  Ronen Manelis דובר צה\"ל רונן מנליס    2708\n",
       " 4      1596076743971510                               QPark    7349\n",
       " ...                 ...                                 ...     ...\n",
       " 11554   310208572352212    Peter Mayhew - The Wookiee Roars    9227\n",
       " 11555      181347337479                     Lexington Mommy    6093\n",
       " 11556   913443162040141                       Kountry Wayne    3472\n",
       " 11557   233251150081246                     Anouk Slootmans    3973\n",
       " 11558   391643350926921                            新聞主播 李亞蒨     555\n",
       " \n",
       " [11559 rows x 3 columns],\n",
       "        source_new_id  target_new_id\n",
       " 0                  0           1490\n",
       " 1                  0           2742\n",
       " 2                  0           7265\n",
       " 3                  0           8076\n",
       " 4                  0           8844\n",
       " ...              ...            ...\n",
       " 67109          11441          11479\n",
       " 67110          10900          11486\n",
       " 67111          11465          11528\n",
       " 67112          11468          11513\n",
       " 67113          11479          11527\n",
       " \n",
       " [67114 rows x 2 columns])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#threadpullexecuter\n",
    "df_merged = load_data(\"fb-pages-public-figure.nodes\", \"fb-pages-public-figure.edges\")\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a306111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Granovetterstyle threshold dynamics\n",
    "#idea is you have 2 states, 0 and 1. based on when you update node, \n",
    "# based on neighbors, if two nodes are from the opposite category, \n",
    "# next time step it will stay same if treshold is met, \n",
    "# it will change if treshold is not met?\n",
    "#normalized\n",
    "#\n",
    "# explore how the structure of your network affects the spread of behaviour or information under\n",
    "#different seeding strategies.\n",
    "\n",
    "\n",
    "\n",
    "#implement 1\n",
    "#either treshold will be the same for all nodes \n",
    "#or treshold will be different for different nodes, draf from a distribution\n",
    "#\n",
    "\n",
    "#compare seeding strategies:\n",
    "#investigate different seeding strategies such as random seeding nodes, \n",
    "# targeting high-degree nodes, or targeting nodes based on their \n",
    "# centrality measures (is that same as highest-betweenness nodes?).\n",
    "#seeding strategies (random, high-degree, high-betweenness, k-core)\n",
    "seeding_strategies = ['random', 'high-degree', 'high-betweenness', 'k-core']\n",
    "\n",
    "\n",
    "#for each strategy, record and compare:\n",
    "#- final fraction of active nodes (so state 1?)\n",
    "# nr of time steps until steady state is reached (or 100% adoption)\n",
    "# shape of the adoption curve over time\n",
    "\n",
    "\n",
    "#choose and document:\n",
    "#Network used (from assignment 2, what is this?)\n",
    "# nr of seeds (1%, 5% )?\n",
    "nr_of_seeds = [0.01, 0.05, 0.1]\n",
    "#treshold values (fixed or distributed)\n",
    "threshold_distributions = {'beta','fixed', 'uniform', 'normal'}\n",
    "#number of simulation repititions (30?) to reduce stochastic effects\n",
    "\n",
    "#with notebook in for loop add something that shows how far in the process you are (how many percent done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17e3b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results = run_experiments(\n",
    "#     N=N,\n",
    "#     k_avg=k_avg,\n",
    "#     ensembles=ENSEMBLES,\n",
    "#     runs_per_setting=RUNS_PER_SETTING,\n",
    "#     threshold_mode=THRESHOLD_MODE,\n",
    "#     phi_mean=PHI_MEAN,\n",
    "#     phi_std=PHI_STD,\n",
    "#     B=B,\n",
    "#     max_steps=MAX_STEPS,\n",
    "#     greedy_R=GREEDY_R\n",
    "# )\n",
    "# df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acf4917",
   "metadata": {},
   "outputs": [],
   "source": [
    "#B_initial = []\n",
    "#N = 300 (what is N?)\n",
    "ensembles = [5,10,15]\n",
    "runs_per_simulationrun = [10,20,30]\n",
    "max_steps = [100,200,300]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
